<!DOCTYPE html>
<!-- START: inst/pkgdown/templates/layout.html --><!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<title>Sensing and tracking 3D environments: All in One View</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" type="text/css" href="assets/styles.css">
<script src="assets/scripts.js" type="text/javascript"></script><!-- mathjax --><script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      config: ["MMLorHTML.js"],
      jax: ["input/TeX","input/MathML","output/HTML-CSS","output/NativeMML", "output/PreviewHTML"],
      extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "fast-preview.js", "AssistiveMML.js", "a11y/accessibility-menu.js"],
      TeX: {
        extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
      },
      tex2jax: {
        inlineMath: [['\\(', '\\)']],
        displayMath: [ ['$$','$$'], ['\\[', '\\]'] ],
        processEscapes: true
      }
    });
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><!-- Responsive Favicon for The Carpentries --><link rel="apple-touch-icon" sizes="180x180" href="apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
<link rel="manifest" href="site.webmanifest">
<link rel="mask-icon" href="safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">
</head>
<body>
    <header id="top" class="navbar navbar-expand-md navbar-light bg-white top-nav incubator"><a class="visually-hidden-focusable skip-link" href="#main-content">Skip to main content</a>
  <div class="container-fluid top-nav-container">
    <div class="col-md-6">
      <div class="large-logo">
        <img alt="Carpentries Incubator" src="assets/images/incubator-logo.svg"><abbr class="badge badge-light" title="This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught." style="background-color: #FF4955; border-radius: 5px">
          <a href="https://cdh.carpentries.org/the-lesson-life-cycle.html#early-development-pre-alpha-through-alpha" class="external-link alert-link" style="color: #000">
            <i aria-hidden="true" class="icon" data-feather="alert-octagon" style="border-radius: 5px"></i>
            Pre-Alpha
          </a>
          <span class="visually-hidden">This lesson is in the pre-alpha phase, which means that it is in early development, but has not yet been taught.</span>
        </abbr>
        
      </div>
    </div>
    <div class="selector-container">
      
      
      <div class="dropdown">
        <button class="btn btn-secondary dropdown-toggle bordered-button" type="button" id="dropdownMenu1" data-bs-toggle="dropdown" aria-expanded="false">
          <i aria-hidden="true" class="icon" data-feather="eye"></i> Learner View <i data-feather="chevron-down"></i>
        </button>
        <ul class="dropdown-menu" aria-labelledby="dropdownMenu1">
<li><button class="dropdown-item" type="button" onclick="window.location.href='instructor/aio.html';">Instructor View</button></li>
        </ul>
</div>
    </div>
  </div>
  <hr></header><nav class="navbar navbar-expand-xl navbar-light bg-white bottom-nav incubator" aria-label="Main Navigation"><div class="container-fluid nav-container">
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle Navigation">
      <span class="navbar-toggler-icon"></span>
      <span class="menu-title">Menu</span>
    </button>
    <div class="nav-logo">
      <img class="small-logo" alt="Carpentries Incubator" src="assets/images/incubator-logo-sm.svg">
</div>
    <div class="lesson-title-md">
      Sensing and tracking 3D environments
    </div>
    <div class="search-icon-sm">
      <!-- TODO: do not show until we have search
        <i role="img" aria-label="search button" data-feather="search"></i>
      -->
    </div>
    <div class="desktop-nav">
      <ul class="navbar-nav me-auto mb-2 mb-lg-0">
<li class="nav-item">
          <span class="lesson-title">
            Sensing and tracking 3D environments
          </span>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="key-points.html">Key Points</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="reference.html#glossary">Glossary</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="profiles.html">Learner Profiles</a>
        </li>
        <li class="nav-item dropdown">
          <button class="nav-link dropdown-toggle" id="navbarDropdown" data-bs-toggle="dropdown" aria-expanded="false">
            More <i data-feather="chevron-down"></i>
          </button>
          <ul class="dropdown-menu" aria-labelledby="navbarDropdown">
<li><a class="dropdown-item" href="reference.html">Reference</a></li>
          </ul>
</li>
      </ul>
</div>
    <form class="d-flex col-md-2 search-form">
      <fieldset disabled>
<input class="form-control me-2 searchbox" type="search" placeholder="Search" aria-label="Search"><button class="btn btn-outline-success tablet-search-button" type="submit">
          <i class="search-icon" data-feather="search" role="img" aria-label="search button"></i>
        </button>
      </fieldset>
</form>
  </div>
<!--/div.container-fluid -->
</nav><div class="col-md-12 mobile-title">
  Sensing and tracking 3D environments
</div>

<aside class="col-md-12 lesson-progress"><div style="width: %" class="percentage">
    %
  </div>
  <div class="progress incubator">
    <div class="progress-bar incubator" role="progressbar" style="width: %" aria-valuenow="" aria-label="Lesson Progress" aria-valuemin="0" aria-valuemax="100">
    </div>
  </div>
</aside><div class="container">
      <div class="row">
        <!-- START: inst/pkgdown/templates/navbar.html -->
<div id="sidebar-col" class="col-lg-4">
  <div id="sidebar" class="sidebar">
      <nav aria-labelledby="flush-headingEleven"><button role="button" aria-label="close menu" alt="close menu" aria-expanded="true" aria-controls="sidebar" class="collapse-toggle" data-collapse="Collapse " data-episodes="Episodes ">
          <i class="search-icon" data-feather="x" role="img"></i>
        </button>
        <div class="sidebar-inner">
          <div class="row mobile-row">
            <div class="col">
              <div class="sidenav-view-selector">
                <div class="accordion accordion-flush" id="accordionFlush9">
                  <div class="accordion-item">
                    <h2 class="accordion-header" id="flush-headingNine">
                      <button class="accordion-button collapsed" id="instructor" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseNine" aria-expanded="false" aria-controls="flush-collapseNine">
                        <i id="eye" aria-hidden="true" class="icon" data-feather="eye"></i> Learner View
                      </button>
                    </h2>
                    <div id="flush-collapseNine" class="accordion-collapse collapse" aria-labelledby="flush-headingNine" data-bs-parent="#accordionFlush2">
                      <div class="accordion-body">
                        <a href="instructor/aio.html">Instructor View</a>
                      </div>
                    </div>
                  </div>
<!--/div.accordion-item-->
                </div>
<!--/div.accordion-flush-->
              </div>
<!--div.sidenav-view-selector -->
            </div>
<!--/div.col -->
      
            <hr>
</div>
<!--/div.mobile-row -->

          <div class="accordion accordion-flush" id="accordionFlush11">
            <div class="accordion-item">

              <button id="chapters" class="accordion-button show" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseEleven" aria-expanded="false" aria-controls="flush-collapseEleven">
                <h2 class="accordion-header chapters" id="flush-headingEleven">
                  EPISODES
                </h2>
              </button>
              <div id="flush-collapseEleven" class="accordion-collapse show collapse" aria-labelledby="flush-headingEleven" data-bs-parent="#accordionFlush11">

                <div class="accordion-body">
                  <div class="accordion accordion-flush" id="accordionFlush1">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading1">
        <a href="index.html">Summary and Setup</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush2">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading2">
        <a href="introduction.html">1. Undertsanding our 3D world</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush3">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading3">
        <a href="technologies-for-sensing.html">2. Technologies for sensing</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush4">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading4">
        <a href="structure-from-motion.html">3. Structure from Motion</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

<div class="accordion accordion-flush" id="accordionFlush5">
  <div class="accordion-item">
    <div class="accordion-header" id="flush-heading5">
        <a href="tracking-in-vr.html">4. Tracking in VR</a>
    </div>
<!--/div.accordion-header-->
        
  </div>
<!--/div.accordion-item-->
</div>
<!--/div.accordion-flush-->

                </div>
              </div>
            </div>

            <hr class="half-width">
<div class="accordion accordion-flush resources" id="accordionFlush12">
              <div class="accordion-item">
                <h2 class="accordion-header" id="flush-headingTwelve">
                  <button class="accordion-button collapsed" id="resources" type="button" data-bs-toggle="collapse" data-bs-target="#flush-collapseTwelve" aria-expanded="false" aria-controls="flush-collapseTwelve">
                    RESOURCES
                  </button>
                </h2>
                <div id="flush-collapseTwelve" class="accordion-collapse collapse" aria-labelledby="flush-headingTwelve" data-bs-parent="#accordionFlush12">
                  <div class="accordion-body">
                    <ul>
<li>
                        <a href="key-points.html">Key Points</a>
                      </li>
                      <li>
                        <a href="reference.html#glossary">Glossary</a>
                      </li>
                      <li>
                        <a href="profiles.html">Learner Profiles</a>
                      </li>
                      <li><a href="reference.html">Reference</a></li>
                    </ul>
</div>
                </div>
              </div>
            </div>
            <hr class="half-width resources">
<a href="aio.html">See all in one page</a>
            

            <hr class="d-none d-sm-block d-md-none">
<div class="d-grid gap-1">
            
            </div>
          </div>
<!-- /div.accordion -->
        </div>
<!-- /div.sidebar-inner -->
      </nav>
</div>
<!-- /div.sidebar -->
  </div>
<!-- /div.sidebar-col -->
<!-- END:   inst/pkgdown/templates/navbar.html-->

        <!-- START: inst/pkgdown/templates/content-extra.html -->
  <div class="col-xl-8 col-lg-12 primary-content">
    <main id="main-content" class="main-content"><div class="container lesson-content">
        
        
<section id="aio-introduction"><p>Content from <a href="introduction.html">Undertsanding our 3D world</a></p>
<hr>
<p>Last updated on 2024-01-23 |
        
        <a href="https://github.com/karina-rodriguez/2023-sensing-3d-environments/edit/main/episodes/introduction.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<div class="overview card">
<h2 class="card-header">Overview</h2>
<div class="row g-0">
<div class="col-md-4">
<div class="card-body">
<div class="inner">
<h3 class="card-title">Questions</h3>
<ul>
<li>How do camera devices understand data and spaces in the
real-world?</li>
<li>What information is recorded by sensor to record objects and
environments?</li>
<li>How do this method support registering motion within a physical 3D
environments?</li>
</ul>
</div>
</div>
</div>
<div class="col-md-8">
<div class="card-body">
<div class="inner bordered">
<h3 class="card-title">Objectives</h3>
<ul>
<li>Have an awareness of the methods available for sensing (or gathering
data) of physical 3D environments and objects.</li>
<li>Understand the different types of sensors, in particular for
detecting motion.</li>
<li>Develop a good understanding of the Structure from motion method,
also known as photogrammetry</li>
<li>Understand the applications of these sensing technologies for
Virtual Reality and Mixed Reality systems.</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<figure><img src="fig/room-wireframe.png" alt="wireframe image room" class="figure mx-auto d-block"><figcaption>Charité University Hospital - Operating Room ©
Queisner M, Pogorzhelskiy M, Remde C, Pratschke J, Sauer IM. from <a href="https://sketchfab.com/3d-models/charite-university-hospital-operating-room-9ec46c4d615a4581a235eebfb162f574" class="external-link">Sketchfab</a></figcaption></figure><p>Tracking our physical environment is an important part of Virtual and
Mixed Reality applications.</p>
<div id="challenge-why-tracking-a-physical-environment" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="challenge-why-tracking-a-physical-environment" class="callout-inner">
<h3 class="callout-title">Challenge: Why tracking a physical
environment?<a class="anchor" aria-label="anchor" href="#challenge-why-tracking-a-physical-environment"></a>
</h3>
<div class="callout-content">
<p>Think why tracking a physical environment is relevant to the
development of VR/MR applications</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1">Output</h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" data-bs-parent="#accordionSolution1" aria-labelledby="headingSolution1">
<div class="accordion-body">
<p>Tracking allows the system to understand how a user is moving with
respect to their physical environment, as well as allowing the user to
seamlessly interact with digital content within the same space.</p>
</div>
</div>
</div>
</div>
<p>Tracking a user is particularly relevant for VR applications.</p>
<p>Increasingly important is tracking the physical space surrounding the
user.</p>
<iframe title="Charité University Hospital - Operating Room" frameborder="0" allowfullscreen mozallowfullscreen="true" webkitallowfullscreen="true" allow="autoplay; 
fullscreen; xr-spatial-tracking" xr-spatial-tracking width="100%;" height="400px;" execution-while-out-of-viewport execution-while-not-rendered web-share src="https://sketchfab.com/models/9ec46c4d615a4581a235eebfb162f574/embed">
</iframe><p><a href="https://sketchfab.com/3d-models/charite-university-hospital-operating-room-9ec46c4d615a4581a235eebfb162f574" class="external-link">Queisner
M, Pogorzhelskiy M, Remde C, Pratschke J, Sauer IM. VolumetricOR: A New
Approach to Simulate Surgical Interventions in Virtual Reality for
Training and Education. Surg Innov. 2022 Jun;29(3):406-415. doi:
10.1177/15533506211054240. Epub 2022 Feb 9. PMID: 35137646; PMCID:
PMC9438748.</a></p>
<p>For instance, to understand how the user moves in space or seamlessly
augment content in our physical space, we need spatial information about
it.</p>
<p><img src="fig/AdobeStock_250036555.jpeg" alt="© REDPIXEL from AdobeStock" class="figure"> An additional challenge is that
things in our space are constantly moving, and being subject to the laws
of physics.</p>
<p>Not only a localization problem, but also a measuring problem. It
requires the computer to determine the exact position of the user and of
obstacles in the surrounding environment.</p>
<p>All of this needs to be computed at interactive rates or fast enough
for the system to operate.</p></section><section id="aio-technologies-for-sensing"><p>Content from <a href="technologies-for-sensing.html">Technologies for sensing</a></p>
<hr>
<p>Last updated on 2024-01-23 |
        
        <a href="https://github.com/karina-rodriguez/2023-sensing-3d-environments/edit/main/episodes/technologies-for-sensing.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<section id="sensing-data"><h2 class="section-heading">Sensing data<a class="anchor" aria-label="anchor" href="#sensing-data"></a>
</h2>
<hr class="half-width">
<figure><img src="fig/AdobeStock_25679833.jpeg" alt="sensors" class="figure mx-auto d-block"><figcaption>Microchip board with sensor © Kadmy from
AdobeStock</figcaption></figure><p><a href="https://www.youtube.com/watch?v=rLxE0VjEkO8" title="Sensors" class="external-link"><img src="https://i.ytimg.com/vi/rLxE0VjEkO8/maxresdefault.jpg" alt="IMAGE ALT TEXT" class="figure"></a></p>
<p>Sensors <strong>sample signals</strong> that measure real world
physical data. This includes sampling:</p>
<ul>
<li>Acceleration forces (accelerometer)</li>
<li>Visible light (photosensors)</li>
<li>Images (CCD sensor)</li>
<li>Distances to objects (laser based detection)</li>
<li>Other data including temperature, humidity, pressure, wind direction
and speed, illumination intensity, vibration intensity, sound intensity,
power-line voltage, chemical concentrations, pollutant levels and vital
body functions.</li>
</ul>
<p><strong>Samples</strong> are converted into numeric values that can
be manipulated by a computer.</p>
<p>Driven by the low cost, many of the devices which we use today
contain sensors. This allows us to sense data all around us.</p>
<p>Most of these sensors are relevant for <a href="https://www.youtube.com/watch?v=DidxdOAkpwA" class="external-link">Internet of
Things</a>, and Internet of Place technologies.</p>
<p>Sensors also allows objects and environments to respond and interact
with their environment.</p>
<p>Building on their wide availability, sensors also allow Virtual
Reality and Mixed Reality to be more affordable.</p>
<div id="challenge-vr-sensors" class="callout challenge">
<div class="callout-square">
<i class="callout-icon" data-feather="zap"></i>
</div>
<div id="challenge-vr-sensors" class="callout-inner">
<h3 class="callout-title">Challenge: VR sensors?<a class="anchor" aria-label="anchor" href="#challenge-vr-sensors"></a>
</h3>
<div class="callout-content">
<p>Think on which sensors are used by VR headests?</p>
</div>
</div>
</div>
<div id="accordionSolution1" class="accordion challenge-accordion accordion-flush">
<div class="accordion-item">
<button class="accordion-button solution-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapseSolution1" aria-expanded="false" aria-controls="collapseSolution1">
  <h4 class="accordion-header" id="headingSolution1">Show me the solution</h4>
</button>
<div id="collapseSolution1" class="accordion-collapse collapse" aria-labelledby="headingSolution1" data-bs-parent="#accordionSolution1">
<div class="accordion-body">
<p>VR headset can include a variety of sensors, including:</p>
<ul>
<li>Inertial Measurement Unit (IMU) to measures force and angular rate
by using a gyroscope, accelerometer and magnetometer.</li>
<li>Image sensor</li>
<li>Proximity sensor</li>
</ul>
</div>
</div>
</div>
</div>
</section><section id="sensing-motion"><h2 class="section-heading">Sensing motion<a class="anchor" aria-label="anchor" href="#sensing-motion"></a>
</h2>
<hr class="half-width">
<figure><img src="fig/Ranex_Smartwares_6000.293_-_board_-_motion_sensor_and_photoresistor-5608.jpg" style="width:40.0%" alt="motion sensor" class="figure mx-auto d-block"><figcaption>Ranex Smartwares 6000.293 - board - motion sensor ©
<a href="https://commons.wikimedia.org/wiki/File:Ranex_Smartwares_6000.293_-_board_-_motion_sensor_and_photoresistor-5608.jpg" class="external-link">Raimond
Spekking</a></figcaption></figure><p>Detects moving objects, particularly people.</p>
<p>Of interest as an interface to systems (e.g. lighting, recording,
home control efficiency)</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/d/dd/Ranex_Smartwares_6000.293-5597.jpg" style="width:30.0%" class="figure"><img src="https://upload.wikimedia.org/wikipedia/commons/2/25/Ranex_Smartwares_6000.293-5600.jpg" style="width:40.0%" alt="Ranex Smartwares 6000.293 © Raimond Spekking" class="figure"></p>
</section><section id="motion-capture"><h2 class="section-heading">Motion capture<a class="anchor" aria-label="anchor" href="#motion-capture"></a>
</h2>
<hr class="half-width">
<p>Detecting motion is of interest to many applications, including the
film and game industry.</p>
<p>This is in particular relevant for animation of digital data. It
allows to transfers the movement of an actor to a digital character.</p>
<p>Requires to have a 3D polygonal mesh which is ready for
animation.</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/8/8b/Motion_Capture_with_Chad_Phantom.png" alt="3d model" class="figure"> However, remember a polygonal meshes are RIGID. They
do not move, unless they undertake a process to animated them.</p>
<p>This requires creating a system of joints (similar than our human
body). This process is known as rigging. A rig is the digital skeleton
formed of joints and bones.</p>
<p>This functionality is offered by modelling packages.</p>
<figure><img src="https://upload.wikimedia.org/wikipedia/commons/9/97/Two_repetitions_of_a_walking_sequence_of_an_individual_recorded_using_a_motion-capture_system.gif" alt="motion" class="figure mx-auto d-block"><figcaption>Two repetitions of a walking sequence recorded using
a motion-capture system. The spatial trajectories of limb movements are
highly similar despite of the timing of movement differing between
repetitions. Data are presented and analyzed in the paper Simultaneous
inference for misaligned multivariate functional data © Lars Lau
Raket</figcaption></figure></section><section id="types-of-tracking-systems"><h2 class="section-heading">Types of Tracking Systems<a class="anchor" aria-label="anchor" href="#types-of-tracking-systems"></a>
</h2>
<hr class="half-width">
<p>There are different type of systems: optical vs non optical
systems.</p>
<div class="section level3">
<h3 id="non-optical-tracking">Non-optical tracking<a class="anchor" aria-label="anchor" href="#non-optical-tracking"></a>
</h3>
<ul>
<li>Based on sensors which measure inertia or mechanical motion,
including accelerometer electromechanical device that measure
acceleration forces.</li>
<li>Come often with easy wearable systems.</li>
<li>Enable accurate motion capture.</li>
</ul>
<p>For example, <a href="https://www.youtube.com/watch?v=-0hSQFbt67U&amp;t=1s" class="external-link">Xsens MVN
solution for 3D Character Animation</a>.</p>
</div>
<div class="section level3">
<h3 id="optical-tracking">Optical tracking<a class="anchor" aria-label="anchor" href="#optical-tracking"></a>
</h3>
<ul>
<li>Use multiple digital cameras.</li>
<li>Based on the information provided by the cameras looking at the
element in motion-tracked within a limited area.</li>
<li>Use position markers in the environment.</li>
<li>Assemble the data into an approximation of the actor’s motion.</li>
<li>The specific technology is based on the role light plays in the
capture process: active versus passive system.</li>
</ul>
<p><a href="https://www.youtube.com/watch?v=O0mLfzbmqcg" class="external-link"><img src="https://i.ytimg.com/vi/O0mLfzbmqcg/maxresdefault.jpg" alt="ALT TEXT" class="figure"></a></p>
<div class="section level4">
<h4 id="active-tracking">Active tracking<a class="anchor" aria-label="anchor" href="#active-tracking"></a>
</h4>
<ul>
<li>Markers are based on light such as LEDs.</li>
<li>Systems illuminate one LED or multiple LEDs at a time.</li>
<li>Software identify markers by their relative positions.</li>
</ul>
</div>
<div class="section level4">
<h4 id="passive-tracking">Passive tracking<a class="anchor" aria-label="anchor" href="#passive-tracking"></a>
</h4>
<p>Based on information provided by one or more digital cameras,
including depth sensors.</p>
<p>This allows for example hand and finger tracking</p>
<p>VR devices now come with depth camera system for finger tracking.</p>
<p><a href="https://www.youtube.com/watch?v=rnlCGw-0R8g" class="external-link"><img src="https://i.ytimg.com/vi/rnlCGw-0R8g/maxresdefault.jpg" alt="ALT TEXT" class="figure"></a></p>
</div>
<div class="section level4">
<h4 id="hybrid-systems">Hybrid systems<a class="anchor" aria-label="anchor" href="#hybrid-systems"></a>
</h4>
<ul>
<li>Use accelerometers and images.</li>
<li>Features in the images are used as markers.</li>
<li>Similar to Structure from Motion technology.</li>
</ul>
<p>Augmented Reality Systems make use of hybrid systems for <a href="https://www.youtube.com/watch?v=2y7NX-HUlMc&amp;t=301s" class="external-link">tracking
capabilities</a>.</p>
</div>
</div>
</section><section id="advantages-and-disadvantages"><h2 class="section-heading">Advantages and disadvantages<a class="anchor" aria-label="anchor" href="#advantages-and-disadvantages"></a>
</h2>
<hr class="half-width">
<p>Non-optical systems are portable but can restrict movement.</p>
<p>Optical systems can be very precise, but are non portable.</p>
</section><section id="performance-and-cost"><h2 class="section-heading">Performance and cost<a class="anchor" aria-label="anchor" href="#performance-and-cost"></a>
</h2>
<hr class="half-width">
<p>An important metric for sensing is the accuracy of the system. This
includes both hardware and software.</p>
<p>Active methods are more accurate, depending on the emitting power of
the light source. But they tend to have a higher cost.</p>
<p>Passive methods are reliant on the ability to find features in the
scene, but have a lower cost. <!--
## Image sensors

In a camera system, 
the image sensor receives incident light (photons) 
and transform it into a digital image.


Active and passive methods.

Active methods provide their own source of energy to illuminate the objects they observe.

For instance LIDAR (Light Detection and Ranging), depth sensor and 3D scanners.
--></p>
<!-- 
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use. 
 -->
</section></section><section id="aio-structure-from-motion"><p>Content from <a href="structure-from-motion.html">Structure from Motion</a></p>
<hr>
<p>Last updated on 2024-01-23 |
        
        <a href="https://github.com/karina-rodriguez/2023-sensing-3d-environments/edit/main/episodes/structure-from-motion.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<p><img src="fig/AdobeStock_656775682.svg" alt="icon" class="figure"> Also known as
photogrammetry.</p>
<p>Passive technique based on multiple acquisitions of the scene taken
by different viewpoints.</p>
<p>Can use a sequence of images (taken separately or as a video).</p>
<p>Artificial lights illuminate the scene and are not exploited for
measuring.</p></section><section id="aio-tracking-in-vr"><p>Content from <a href="tracking-in-vr.html">Tracking in VR</a></p>
<hr>
<p>Last updated on 2024-01-23 |
        
        <a href="https://github.com/karina-rodriguez/2023-sensing-3d-environments/edit/main/episodes/tracking-in-vr.Rmd" class="external-link">Edit this page <i aria-hidden="true" data-feather="edit"></i></a></p>
<div class="text-end">
          <button role="button" aria-pressed="false" tabindex="0" id="expand-code" class="pull-right" data-expand="Expand All Solutions " data-collapse="Collapse All Solutions "> Expand All Solutions <i aria-hidden="true" data-feather="plus"></i></button>
        </div>
<p>Virtual Reality (VR) headsets are distinct from regular 3D displays
in that they are tracked. This allows the system to provide 3 Degrees or
6 Degrees of Freedom.</p>
<figure><img src="https://upload.wikimedia.org/wikipedia/commons/3/33/Positional_tracking_in_virtual_reality.png" alt="positional tracking" class="figure mx-auto d-block"><figcaption>Positional tracking in virtual reality © Ilsladkih at
<a href="https://commons.wikimedia.org/wiki/File:Positional_tracking_in_virtual_reality.png" class="external-link">Wikimedia</a></figcaption></figure><p>Tracking in VR is also known as a positional tracking or pose
tracking. It allows the headset to capture, follow, and get information
about an object’s orientation and position, to be transferred to an
application for further processing.</p>
<figure><img src="https://developers.google.com/static/ml-kit/images/vision/pose-detection/jump.gif" alt="pose tracking" class="figure mx-auto d-block"><figcaption>Pose estimation library from Google © <a href="https://developers.google.com/ml-kit/vision/pose-detection" class="external-link">Google</a></figcaption></figure><p>See examples of Pose Estimation libraries:</p>
<ul>
<li>Media Pipe: <a href="https://huggingface.co/spaces/hysts/mediapipe-pose-estimation" class="external-link">https://huggingface.co/spaces/hysts/mediapipe-pose-estimation</a>
</li>
<li>Tensor Flow: <a href="https://www.tensorflow.org/lite/examples/pose_estimation/overview" class="external-link">https://www.tensorflow.org/lite/examples/pose_estimation/overview</a>
Pose detection</li>
</ul>
<figure><img src="https://storage.googleapis.com/download.tensorflow.org/example_images/movenet_demo.gif" alt="" class="figure mx-auto d-block"><figcaption>Pose estimation library from Tensor Flow © <a href="https://www.tensorflow.org/lite/examples/pose_estimation/overview" class="external-link">Tensor
Flow</a></figcaption></figure><section id="what-do-we-track"><h2 class="section-heading">What do we track?<a class="anchor" aria-label="anchor" href="#what-do-we-track"></a>
</h2>
<hr class="half-width">
<p>In a VR system, the aim is to track information of the user,
including:</p>
<ul>
<li>Position and orientation of the user’s head.</li>
<li>Controllers and other important objects.</li>
<li>Hands</li>
</ul>
<p>In AR systems, object, images, or markers are used to determine the
user’s position and orientation.</p>
</section><section id="types-of-tracking"><h2 class="section-heading">Types of tracking<a class="anchor" aria-label="anchor" href="#types-of-tracking"></a>
</h2>
<hr class="half-width">
<p>As before, tracking can be optical vs non optical. We will focus on
the optical, and make a distinction between outside-in and inside-out
tracking.</p>
<figure><img src="https://xinreality.com/mediawiki/images/5/5a/Inside_out_vs._outside_in_tracking.png" alt="outside in and inside out" class="figure mx-auto d-block"><figcaption>Inside-out vs. outside-in tracking © <a href="https://xinreality.com/wiki/File:Inside_out_vs._outside_in_tracking.png" class="external-link">Ishii
from under CC BY-SA 3.0</a></figcaption></figure><div class="section level3">
<h3 id="optical-outside-in-tracking">Optical outside-in tracking<a class="anchor" aria-label="anchor" href="#optical-outside-in-tracking"></a>
</h3>
<p>In this type of tracking, cameras are placed in stationary locations
in the environment to track the position of markers on the tracked
device. For example, the HTC VIVE uses outside-in tracking.</p>
<p>IR LEDs on its headset and controllers allow external cameras in the
environment to read their positions.</p>
</div>
</section><section id="optical-inside-out-tracking"><h2 class="section-heading">Optical Inside-out tracking<a class="anchor" aria-label="anchor" href="#optical-inside-out-tracking"></a>
</h2>
<hr class="half-width">
<p>The camera is placed on the tracked device and looks outward to
determine its location in the environment.</p>
<p>Headsets have multiple cameras facing different directions to get
views of its entire surroundings.</p>
<p>Can work with or without markers.</p>
</section><section id="slam-simultaneous-localization-and-mapping"><h2 class="section-heading">SLAM (Simultaneous localization and mapping)<a class="anchor" aria-label="anchor" href="#slam-simultaneous-localization-and-mapping"></a>
</h2>
<hr class="half-width">
<p>Markerless tracking, such as on the Oculus Quest.</p>
<p>Algorithms to construct or update a map of an unknown environment
while simultaneously keeping track of an agent’s location within it</p>
<p>A 3D map of the environment is generated in real time.</p>
<p><a href="https://www.youtube.com/watch?app=desktop&amp;v=J5oW7r-2dlM" title="tracking" class="external-link"><img src="https://i.ytimg.com/vi/J5oW7r-2dlM/maxresdefault.jpg" alt="IMAGE ALT TEXT" class="figure"></a></p>
<p>Further information: <a href="https://xinreality.com/wiki/Main_Page" class="external-link uri">https://xinreality.com/wiki/Main_Page</a></p>
<!-- 
Place links that you need to refer to multiple times across pages here. Delete
any links that you are not going to use. 
 -->
</section></section>
</div>
    </main>
</div>
<!-- END  : inst/pkgdown/templates/content-extra.html -->

      </div>
<!--/div.row-->
      		<footer class="row footer mx-md-3"><hr>
<div class="col-md-6">
        <p>This lesson is subject to the <a href="CODE_OF_CONDUCT.html">Code of Conduct</a></p>
        <p>
        
        <a href="https://github.com/karina-rodriguez/2023-sensing-3d-environments/edit/main/README.md" class="external-link">Edit on GitHub</a>
        
	
        | <a href="https://github.com/karina-rodriguez/2023-sensing-3d-environments/blob/main/CONTRIBUTING.md" class="external-link">Contributing</a>
        | <a href="https://github.com/karina-rodriguez/2023-sensing-3d-environments/" class="external-link">Source</a></p>
				<p><a href="https://github.com/karina-rodriguez/2023-sensing-3d-environments/blob/main/CITATION" class="external-link">Cite</a> | <a href="mailto:K.rodriguez@brigthon.ac.uk">Contact</a> | <a href="https://carpentries.org/about/" class="external-link">About</a></p>
			</div>
			<div class="col-md-6">
        
        <p>Materials licensed under <a href="LICENSE.html">CC-BY 4.0</a> by the authors</p>
        
        <p>Template licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0/" class="external-link">CC-BY 4.0</a> by <a href="https://carpentries.org/" class="external-link">The Carpentries</a></p>
        <p>Built with <a href="https://github.com/carpentries/sandpaper/tree/0.16.2" class="external-link">sandpaper (0.16.2)</a>, <a href="https://github.com/carpentries/pegboard/tree/0.7.3" class="external-link">pegboard (0.7.3)</a>, and <a href="https://github.com/carpentries/varnish/tree/1.0.1" class="external-link">varnish (1.0.1)</a></p>
			</div>
		</footer>
</div> <!-- / div.container -->
	<div id="to-top">
		<a href="#top">
      <i class="search-icon" data-feather="arrow-up" role="img" aria-label="Back To Top"></i><br><!-- <span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top --><span class="d-none d-sm-none d-md-none d-lg-none d-xl-block">Back</span> To Top
		</a>
	</div>
  <script type="application/ld+json">
    {
  "@context": "https://schema.org",
  "@type": "TrainingMaterial",
  "@id": "https://karina-rodriguez.github.io/2023-sensing-3d-environments/aio.html",
  "inLanguage": "en",
  "dct:conformsTo": "https://bioschemas.org/profiles/TrainingMaterial/1.0-RELEASE",
  "description": "A Carpentries Lesson teaching foundational data and coding skills to researchers worldwide",
  "keywords": "photogrammetry, 3D digitisation, The Carpentries",
  "name": "All in One View",
  "creativeWorkStatus": "active",
  "url": "https://karina-rodriguez.github.io/2023-sensing-3d-environments/aio.html",
  "identifier": "https://karina-rodriguez.github.io/2023-sensing-3d-environments/aio.html",
  "dateCreated": "2023-11-13",
  "dateModified": "2024-01-23",
  "datePublished": "2024-01-23"
}

  </script><script>
		feather.replace();
	</script><!-- Matomo
    2022-11-07: we have gotten a notification that we have an overage for our
    tracking and I'm pretty sure this has to do with Workbench usage.
    Considering that I am not _currently_ using this tracking because I do not
    yet know how to access the data, I am turning this off for now.
  <script>
    var _paq = window._paq = window._paq || [];
    /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
    _paq.push(["setDocumentTitle", document.domain + "/" + document.title]);
    _paq.push(["setDomains", ["*.preview.carpentries.org","*.datacarpentry.github.io","*.datacarpentry.org","*.librarycarpentry.github.io","*.librarycarpentry.org","*.swcarpentry.github.io", "*.carpentries.github.io"]]);
    _paq.push(["setDoNotTrack", true]);
    _paq.push(["disableCookies"]);
    _paq.push(['trackPageView']);
    _paq.push(['enableLinkTracking']);
    (function() {
          var u="https://carpentries.matomo.cloud/";
          _paq.push(['setTrackerUrl', u+'matomo.php']);
          _paq.push(['setSiteId', '1']);
          var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
          g.async=true; g.src='https://cdn.matomo.cloud/carpentries.matomo.cloud/matomo.js'; s.parentNode.insertBefore(g,s);
        })();
  </script>
  End Matomo Code -->
</body>
</html><!-- END:   inst/pkgdown/templates/layout.html-->

